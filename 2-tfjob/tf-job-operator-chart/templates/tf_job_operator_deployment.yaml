apiVersion: v1
kind: ConfigMap
metadata:
  name: tf-job-operator-config
  namespace: default
data:
  controller_config_file.yaml: |
    accelerators:
      alpha.kubernetes.io/nvidia-gpu:
        envVars:
          - name: LD_LIBRARY_PATH
            value: /usr/lib/nvidia:/usr/lib/x86_64-linux-gnu
        volumes:
          - name: bin
            mountPath: /usr/local/nvidia/bin 
            hostPath: /usr/lib/nvidia-378/bin
          - name: lib # optional
            mountPath: /usr/lib/nvidia
            hostPath:  /usr/lib/nvidia-378
          - name: libcuda
            mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.1
            hostPath: /usr/lib/x86_64-linux-gnu/libcuda.so.1 
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: tf-job-operator
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: tf-job-operator
    spec:
      containers:
      - name: tf-job-operator
        image: wbuchwalter/tf-operator:tensorboard
        command:
          - /opt/mlkube/tf_operator
          - --controller_config_file=/etc/config/controller_config_file.yaml
          - -alsologtostderr
          - -v=1
        env:
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name

        volumeMounts:
          - name: config-volume
            mountPath: /etc/config
      volumes:
        - name: config-volume
          configMap:
            name: tf-job-operator-config